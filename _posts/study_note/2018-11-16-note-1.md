---
layout: post
title: "The difference between CNN and FCNN"
date: 2018-11-12
categories: [Study notes]
tags: [CNN, class models]
---
FCNN(Fully Convolutional Neural Network), unlike the classic CNN, which use the Fully Connected layers after the Convolutional layers in the network, the FCNN can take input of arbitrary size.

In CNN, suppose we have one output feature and 'n' input features for all the samples to train the model, but we can't feed an input with 'n+1' features to the above model because this will cause the change in the weight dimensions.

Fully convolutional training takes the whole M x M image and produces outputs for all subimages in a single ConvNet forward pass.
Patchwise training explicitly crops out the subimages and produces outputs for each subimage in independent forward passes. Therefore, fully convolutional training is usually substantially faster than pathwise training.

So, for fully convolutional training, you make updates like this:

Input whole MxM image (or multiple images)
Push through ConvNet -> get an entire map of outputs (maximum size MxM per image, possibly smaller)
Make updates using the loss of all outputs
