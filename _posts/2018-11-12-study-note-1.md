---
layout: post
title: "Study Note - Course 4: Convolutional Neural Networks"
date: 2018-11-12
---

- course source: [deeplearning.ai](https://www.coursera.org/learn/convolutional-neural-networks/home/welcome)

## I. Padding
* Valid convolution: no padding
* Same convolution: Pad so that output size is the same as the input size

## II. Summary of convolutions

* **n x n** image __f x f__ filter
* padding __p__
* stride __s__
* output size: (n + 2p - f )/s + 1

## III. MaxPooling and AveragePooling
* Hyperparameters:
1. filter, normally : f=2
2. stride, normally: s=2
* No parameters to learn

## IV. Why convolutions
* Parameter sharing
* Sparsity of connections

## V. Classic networks

* LeNet-5_1998
Conv -- Pool -- Conv -- Pool -- FC
* AlexNet_2012
  * Pros:
  1. ~60 million parameters
  2. ReLu activation

  * Not used today:
  1. Multiple GPUs
  2. Local Response Normalization

* VGG-16_2015
conv 3x3 filter s =1 same padding
max pool 2x2 s =2
simplify the architecture
1. ~138 million parameters

## VI. ResNet 152 layers
__skip connections__
* Enable the network to get deeper without harming the performance of the network. When the network gets deeper and deeper, it's difficult to choose parameters to learn idendity function, while using the skip connections will solve this proble.
* Use the skip connections allows to add extra layers without hurting the performance of the network
* Skip connection also allows the gradient to be directly backpropagated to earlier layers.
__Residuel network__


## VII. Inception 2014
> * How to solve the problem of computational cost: add a 1x1 conv layer (bottleneck) to reduce the computational cost.
* The inception module do the convolution and max pooling in the same time and concatenate the result.
* Additional side branches: take some hidden layer to make some prediction. prevent overfitting

* You can use 1x1 Conv layer to reduce nc, but not nh, nw
* You can use pooling layer to reduce nh, nw, but not nc

## VIII. Transfer learning
Download weights that someone else has already trained on the network architecture and use that as pre-training. And transfer that to a new task that I might be interested in.
Use it as an initial neural network.
1. Download some open source implementation of a neural network, download not just the code but also the __weights__.
* If you have a very small training set, you can freeze all the parameters in the earlier layers and train only your own layer.
* If you have a larger training set, you can freeze some layers and train the other layers. Or add your own hidden layers.
* If you have a lot of data, you can take the open source network and weights, and use the whole thing just as initialization and train the whole network.

## IX. Data Augmentation
- __*Mirroring*__
- __*Random Cropping*__
- Rotation
- Shearing
- Local warping

- __*Color shifting*__
> PCA(AlexNet paper) color Augmentation

## X. Two sources of knowledge
* Labeled Data
* Hand engineered features/network architecture/other components
For computer vision, there is not enough data, so it relys more on hand engineering.

## XI. Doing well on benchmarks/winning competitions
* Ensembling (time consuming) -- Train several networks independently and average their outputs. yhat.
* Multi-crop at test time (time consuming) -- Run classifier on multiple versions of test images and average results

DO NOT USE IT FOR PRODUCT DEVELOPMENT IN THE REAL INDUSTRY

## XII. Use open source code
* use architectures of networks published in the literature
* use open source implementation if possible
* use pretrained models and fine-tune on your dataset

## XII. Object detection
>* Classification with localization --> 1 big object
* Detection --> multiple objects

To locate the object, we output a bounding box: *4 parameters: bx, by, bh, bw*

#### Landmark detection
convolutional implementation of sliding windows detection algorithm, use only one forward pass to predict the output. More efficient
*  YOLO algorithm
  * Assign an object to a grid cell if the midpoint of the object is the grid cell.
  * One object is assigned to only one grid cell.
  * work very fast, even with the real time application
  * By convention, the bounding box's position is calculted relatively to the grid cell, the bx and by is between the 0 and 1. bh and bw could be larger than 1.

#### Intersection Over Union
* computes the size of the intersection over union of two bounding boxes of one object, divided by the size of the union.
* if IoU >= 0.5, it's correct.
* The higher the IoU, the more accuracy the bounding box.

#### Non-max Suppression
* A way to make sure that your algorithm detects each object only once. (one detection per object)
* Run object classification and localization algorithm for every one of these spilt cells
